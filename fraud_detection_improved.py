#!/usr/bin/env python3
"""
Fraud Detection Model - Advanced Implementation
===============================================

Autor: Data Scientist Senior
DescripciÃ³n: ImplementaciÃ³n mejorada para detecciÃ³n de fraude que aborda las 
            debilidades del modelo original y proporciona una soluciÃ³n robusta.

Este script implementa las 4 fases del anÃ¡lisis:
1. CrÃ­tica Constructiva y Plan de AcciÃ³n
2. Preprocesamiento de Datos Avanzado y Feature Engineering  
3. Modelado y OptimizaciÃ³n
4. EvaluaciÃ³n Rigurosa del Modelo y Conclusiones
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold, ParameterGrid
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import KNNImputer
from sklearn.metrics import (classification_report, confusion_matrix, 
                           precision_score, recall_score, f1_score, 
                           roc_auc_score, roc_curve, accuracy_score)
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("FRAUD DETECTION MODEL - ADVANCED IMPLEMENTATION")
print("="*80)

# =====================================================================
# FASE 1: CRÃTICA CONSTRUCTIVA Y PLAN DE ACCIÃ“N
# =====================================================================

print("\n" + "="*60)
print("FASE 1: CRÃTICA CONSTRUCTIVA Y PLAN DE ACCIÃ“N")
print("="*60)

print("""
ANÃLISIS CRÃTICO DE LA METODOLOGÃA ACTUAL:

1. MANEJO INADECUADO DE VALORES NULOS:
   âŒ Problema: Reemplazar todos los valores NaN por 0
   ğŸ” Por quÃ© es problemÃ¡tico: 
      - Introduce sesgo artificial en el modelo
      - Puede crear patrones falsos donde no los hay
      - Diferentes variables requieren estrategias de imputaciÃ³n distintas
   âœ… SoluciÃ³n: ImputaciÃ³n sofisticada usando KNNImputer o estrategias especÃ­ficas

2. CODIFICACIÃ“N INCORRECTA DE VARIABLES CATEGÃ“RICAS:
   âŒ Problema: Asignar "pesos" numÃ©ricos arbitrarios a variables de texto
   ğŸ” Por quÃ© es problemÃ¡tico:
      - Crea relaciones ordinales artificiales que no existen
      - El modelo interpreta incorrectamente la distancia entre categorÃ­as
      - Puede llevr a conclusiones errÃ³neas sobre importancia de features
   âœ… SoluciÃ³n: One-Hot Encoding estÃ¡ndar

3. MÃ‰TRICAS DE EVALUACIÃ“N INSUFICIENTES:
   âŒ Problema: Solo usar precisiÃ³n (accuracy) como mÃ©trica
   ğŸ” Por quÃ© es problemÃ¡tico para fraude:
      - En datasets desbalanceados, accuracy puede ser muy engaÃ±osa
      - Un modelo que clasifica todo como "no fraude" podrÃ­a tener 80% accuracy
      - No mide la capacidad real de detectar fraudes (recall)
   âœ… SoluciÃ³n: MÃ©tricas completas - Precision, Recall, F1-Score, ROC-AUC

4. FALTA DE MANEJO DEL DESBALANCE DE CLASES:
   âŒ Problema: No abordar el desbalance 63.5% vs 36.5%
   ğŸ” Por quÃ© es problemÃ¡tico:
      - El modelo se sesga hacia la clase mayoritaria
      - Puede tener buen accuracy pero muy mal recall para fraudes
   âœ… SoluciÃ³n: SMOTE para balancear las clases

5. AUSENCIA DE PREPROCESAMIENTO AVANZADO:
   âŒ Problema: No escalar variables, no analizar correlaciones
   ğŸ” Por quÃ© es problemÃ¡tico:
      - Algoritmos como Logistic Regression son sensibles a la escala
      - Variables con rangos diferentes dominan el modelo
   âœ… SoluciÃ³n: StandardScaler y anÃ¡lisis de features

PLAN DE ACCIÃ“N ESTRUCTURADO:
1. EDA completo con visualizaciones
2. ImputaciÃ³n avanzada de valores faltantes  
3. CodificaciÃ³n apropiada de categÃ³ricas
4. Escalado de features numÃ©ricas
5. Manejo del desbalance con SMOTE
6. ComparaciÃ³n de mÃºltiples algoritmos
7. OptimizaciÃ³n de hiperparÃ¡metros
8. EvaluaciÃ³n rigurosa con mÃ©tricas de negocio
""")

# =====================================================================
# FASE 2: PREPROCESAMIENTO DE DATOS AVANZADO Y FEATURE ENGINEERING
# =====================================================================

print("\n" + "="*60)
print("FASE 2: PREPROCESAMIENTO DE DATOS AVANZADO Y FEATURE ENGINEERING")
print("="*60)

# Cargar datos
print("ğŸ“Š Cargando datasets...")
df_train = pd.read_excel('entrenamiento_fraude.xlsx')
df_test = pd.read_excel('testeo_fraude.xlsx')
df_eval = pd.read_excel('base_evaluada.xlsx')

print(f"âœ… Dataset entrenamiento: {df_train.shape}")
print(f"âœ… Dataset testeo: {df_test.shape}")  
print(f"âœ… Dataset evaluaciÃ³n: {df_eval.shape}")

# EDA Inicial
print("\nğŸ“ˆ ANÃLISIS EXPLORATORIO INICIAL:")
print(f"Variables totales: {len(df_train.columns)}")
print(f"Variables numÃ©ricas: {len(df_train.select_dtypes(include=[np.number]).columns)}")
print(f"Variables categÃ³ricas: {len(df_train.select_dtypes(include=['object']).columns)}")
print(f"Valores faltantes totales: {df_train.isnull().sum().sum()}")

# AnÃ¡lisis del desbalance de clases
print("\nâš–ï¸ ANÃLISIS DEL BALANCE DE CLASES:")
class_distribution = df_train['fraude'].value_counts()
print(f"Clase 0 (No Fraude): {class_distribution[0]} ({class_distribution[0]/len(df_train)*100:.1f}%)")
print(f"Clase 1 (Fraude): {class_distribution[1]} ({class_distribution[1]/len(df_train)*100:.1f}%)")
print(f"Ratio de desbalance: {class_distribution[0]/class_distribution[1]:.2f}:1")

if class_distribution[0]/class_distribution[1] > 1.5:
    print("âš ï¸ DATASET DESBALANCEADO DETECTADO - Se aplicarÃ¡ SMOTE")
else:
    print("âœ… Dataset relativamente balanceado")

# Identificar variables categÃ³ricas
categorical_features = ['descri_apli_prod_ben', 'marca_timeout', 'marca_host_no_resp']
numerical_features = [col for col in df_train.columns 
                     if col not in categorical_features + ['radicado', 'fraude']]

print(f"\nğŸ”¤ Variables categÃ³ricas identificadas: {categorical_features}")
print(f"ğŸ”¢ Variables numÃ©ricas: {len(numerical_features)}")

# AnÃ¡lisis de valores faltantes por tipo de variable
print("\nğŸ•³ï¸ ANÃLISIS DE VALORES FALTANTES:")
missing_analysis = df_train.isnull().sum()
missing_analysis = missing_analysis[missing_analysis > 0].sort_values(ascending=False)

for col, missing_count in missing_analysis.head(10).items():
    missing_pct = missing_count / len(df_train) * 100
    col_type = "categÃ³rica" if col in categorical_features else "numÃ©rica"
    print(f"   {col} ({col_type}): {missing_count} ({missing_pct:.1f}%)")

# Separar features y target
X = df_train.drop(['radicado', 'fraude'], axis=1)
y = df_train['fraude']

print("\nğŸ”§ APLICANDO PREPROCESAMIENTO AVANZADO...")

# 1. Estrategia de ImputaciÃ³n Sofisticada
print("1ï¸âƒ£ ImputaciÃ³n avanzada de valores faltantes:")
print("   â€¢ Variables numÃ©ricas: KNNImputer (k=5) - mÃ¡s sofisticado que mediana")
print("   â€¢ Variables categÃ³ricas: Moda (valor mÃ¡s frecuente)")

# Para categÃ³ricas: imputar con moda
for col in categorical_features:
    if col in X.columns:
        mode_value = X[col].mode().iloc[0] if not X[col].mode().empty else 'Unknown'
        X[col] = X[col].fillna(mode_value)
        print(f"   âœ… {col}: {X[col].isnull().sum()} valores faltantes restantes")

# Para numÃ©ricas: KNNImputer
numerical_cols_in_X = [col for col in numerical_features if col in X.columns]
if len(numerical_cols_in_X) > 0:
    knn_imputer = KNNImputer(n_neighbors=5)
    X[numerical_cols_in_X] = knn_imputer.fit_transform(X[numerical_cols_in_X])
    print(f"   âœ… Variables numÃ©ricas: KNNImputer aplicado a {len(numerical_cols_in_X)} columnas")

print(f"   âœ… Valores faltantes restantes: {X.isnull().sum().sum()}")

# 2. One-Hot Encoding para variables categÃ³ricas
print("\n2ï¸âƒ£ One-Hot Encoding para variables categÃ³ricas:")
print("   ğŸ¯ Ventajas sobre asignaciÃ³n de pesos:")
print("      â€¢ No crea relaciones ordinales artificiales")
print("      â€¢ Cada categorÃ­a es independiente")
print("      â€¢ Interpretabilidad clara del modelo")

X_encoded = pd.get_dummies(X, columns=categorical_features, prefix=categorical_features, drop_first=True)
print(f"   âœ… Dimensiones despuÃ©s de encoding: {X_encoded.shape}")
print(f"   âœ… Nuevas columnas categÃ³ricas creadas: {X_encoded.shape[1] - len(numerical_cols_in_X)}")

# 3. Escalado de caracterÃ­sticas
print("\n3ï¸âƒ£ Escalado de caracterÃ­sticas numÃ©ricas:")
print("   ğŸ¯ Importancia del escalado:")
print("      â€¢ Algoritmos como Logistic Regression son sensibles a la escala")
print("      â€¢ Mejora convergencia y performance")
print("      â€¢ Evita que variables con rangos grandes dominen el modelo")

scaler = StandardScaler()
numerical_cols_encoded = [col for col in X_encoded.columns if col in numerical_cols_in_X]
X_scaled = X_encoded.copy()
X_scaled[numerical_cols_encoded] = scaler.fit_transform(X_encoded[numerical_cols_encoded])
print(f"   âœ… {len(numerical_cols_encoded)} variables numÃ©ricas escaladas")

# 4. DivisiÃ³n de datos
print("\n4ï¸âƒ£ DivisiÃ³n estratificada de datos:")
X_train, X_val, y_train, y_val = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)
print(f"   âœ… Entrenamiento: {X_train.shape[0]} muestras")
print(f"   âœ… ValidaciÃ³n: {X_val.shape[0]} muestras")
print(f"   âœ… DistribuciÃ³n mantenida en ambos conjuntos")

# 5. Manejo del desbalance con SMOTE
print("\n5ï¸âƒ£ Manejo del desbalance de clases con SMOTE:")
print("   ğŸ¯ SMOTE (Synthetic Minority Over-sampling Technique):")
print("      â€¢ Genera muestras sintÃ©ticas de la clase minoritaria")
print("      â€¢ Mejor que duplicar datos existentes")
print("      â€¢ Solo se aplica en entrenamiento, NO en validaciÃ³n")

original_distribution = pd.Series(y_train).value_counts()
print(f"   ğŸ“Š DistribuciÃ³n original: {dict(original_distribution)}")

smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

balanced_distribution = pd.Series(y_train_balanced).value_counts()
print(f"   ğŸ“Š DistribuciÃ³n despuÃ©s de SMOTE: {dict(balanced_distribution)}")
print(f"   âœ… Dataset balanceado: {X_train_balanced.shape[0]} muestras totales")

print("\nğŸ‰ PREPROCESAMIENTO COMPLETADO:")
print(f"   â€¢ Datos finales entrenamiento: {X_train_balanced.shape}")
print(f"   â€¢ Features totales: {X_train_balanced.shape[1]}")
print(f"   â€¢ Clases balanceadas: âœ…")
print(f"   â€¢ Datos escalados: âœ…")
print(f"   â€¢ Variables categÃ³ricas codificadas: âœ…")

# =====================================================================
# FASE 3: MODELADO Y OPTIMIZACIÃ“N  
# =====================================================================

print("\n" + "="*60)
print("FASE 3: MODELADO Y OPTIMIZACIÃ“N")
print("="*60)

print("\nğŸ¤– SELECCIÃ“N Y COMPARACIÃ“N DE ALGORITMOS:")
print("   ğŸ¯ Por quÃ© mÃºltiples algoritmos:")
print("      â€¢ Diferentes algoritmos capturan diferentes patrones")
print("      â€¢ Permite encontrar el mejor para este problema especÃ­fico")
print("      â€¢ Reduce overfitting y aumenta robustez")

# Definir modelos a comparar
models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),
    'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss')
}

print(f"\nğŸ“‹ Algoritmos a evaluar:")
for name, model in models.items():
    print(f"   â€¢ {name}")

# Cross-validation strategy
cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
print(f"\nğŸ”„ Estrategia de validaciÃ³n cruzada: {cv_strategy.n_splits}-fold estratificada")

# Evaluar modelos base
print("\nğŸƒâ€â™‚ï¸ EVALUACIÃ“N INICIAL DE MODELOS (sin optimizar):")
model_results = {}

for name, model in models.items():
    print(f"\n   ğŸ” Evaluando {name}...")
    
    # Cross-validation scores
    cv_scores = cross_val_score(model, X_train_balanced, y_train_balanced, 
                               cv=cv_strategy, scoring='roc_auc', n_jobs=-1)
    
    # Fit model and predict on validation
    model.fit(X_train_balanced, y_train_balanced)
    y_pred = model.predict(X_val)
    y_pred_proba = model.predict_proba(X_val)[:, 1]
    
    # Calculate metrics
    accuracy = accuracy_score(y_val, y_pred)
    precision = precision_score(y_val, y_pred)
    recall = recall_score(y_val, y_pred)
    f1 = f1_score(y_val, y_pred)
    auc_score = roc_auc_score(y_val, y_pred_proba)
    
    model_results[name] = {
        'cv_auc_mean': cv_scores.mean(),
        'cv_auc_std': cv_scores.std(),
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'auc': auc_score,
        'model': model
    }
    
    print(f"      CV AUC: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
    print(f"      ValidaciÃ³n - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}")

# Encontrar el mejor modelo base
best_model_name = max(model_results.keys(), key=lambda x: model_results[x]['cv_auc_mean'])
print(f"\nğŸ† MEJOR MODELO BASE: {best_model_name}")
print(f"   AUC promedio en CV: {model_results[best_model_name]['cv_auc_mean']:.4f}")

# OptimizaciÃ³n de hiperparÃ¡metros para el mejor modelo
print(f"\nâš™ï¸ OPTIMIZACIÃ“N DE HIPERPARÃMETROS - {best_model_name}:")
print("   ğŸ¯ GridSearchCV para encontrar la mejor combinaciÃ³n de parÃ¡metros")

if best_model_name == 'Logistic Regression':
    param_grid = {
        'C': [0.1, 1, 10],
        'penalty': ['l1', 'l2'],
        'solver': ['liblinear']
    }
elif best_model_name == 'Random Forest':
    param_grid = {
        'n_estimators': [100, 200],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1, 2]
    }
else:  # XGBoost
    param_grid = {
        'n_estimators': [100, 200],
        'max_depth': [3, 6],
        'learning_rate': [0.1, 0.2],
        'subsample': [0.8, 1.0]
    }

# GridSearch
print(f"   ğŸ” Buscando entre {len(list(ParameterGrid(param_grid)))} combinaciones...")
best_base_model = models[best_model_name]
grid_search = GridSearchCV(
    best_base_model, param_grid, cv=cv_strategy, 
    scoring='roc_auc', n_jobs=-1, verbose=0
)

grid_search.fit(X_train_balanced, y_train_balanced)
best_model_optimized = grid_search.best_estimator_

print(f"   âœ… Mejores parÃ¡metros encontrados:")
for param, value in grid_search.best_params_.items():
    print(f"      {param}: {value}")
print(f"   âœ… Mejor AUC en CV: {grid_search.best_score_:.4f}")

# =====================================================================
# FASE 4: EVALUACIÃ“N RIGUROSA DEL MODELO Y CONCLUSIONES
# =====================================================================

print("\n" + "="*60)
print("FASE 4: EVALUACIÃ“N RIGUROSA DEL MODELO Y CONCLUSIONES")
print("="*60)

print("\nğŸ“Š EVALUACIÃ“N COMPLETA DEL MODELO OPTIMIZADO:")
print("   ğŸ¯ MÃ©tricas esenciales para detecciÃ³n de fraude:")
print("      â€¢ Precision: Â¿QuÃ© % de alertas de fraude son realmente fraude?")
print("      â€¢ Recall: Â¿QuÃ© % de fraudes reales detectamos?")
print("      â€¢ F1-Score: Balance entre Precision y Recall")
print("      â€¢ ROC-AUC: Capacidad discriminativa general")

# Predicciones finales
y_pred_final = best_model_optimized.predict(X_val)
y_pred_proba_final = best_model_optimized.predict_proba(X_val)[:, 1]

# MÃ©tricas finales
final_accuracy = accuracy_score(y_val, y_pred_final)
final_precision = precision_score(y_val, y_pred_final)
final_recall = recall_score(y_val, y_pred_final)
final_f1 = f1_score(y_val, y_pred_final)
final_auc = roc_auc_score(y_val, y_pred_proba_final)

print(f"\nğŸ“ˆ MÃ‰TRICAS FINALES DEL MODELO OPTIMIZADO:")
print(f"   â€¢ Accuracy: {final_accuracy:.4f} ({final_accuracy*100:.1f}%)")
print(f"   â€¢ Precision: {final_precision:.4f} ({final_precision*100:.1f}%)")
print(f"   â€¢ Recall: {final_recall:.4f} ({final_recall*100:.1f}%)")
print(f"   â€¢ F1-Score: {final_f1:.4f}")
print(f"   â€¢ ROC-AUC: {final_auc:.4f}")

# Matriz de confusiÃ³n
print(f"\nğŸ¯ MATRIZ DE CONFUSIÃ“N:")
cm = confusion_matrix(y_val, y_pred_final)
tn, fp, fn, tp = cm.ravel()

print(f"                 PredicciÃ³n")
print(f"               No Fraude  Fraude")
print(f"Real No Fraude    {tn:4d}    {fp:4d}")
print(f"Real Fraude       {fn:4d}    {tp:4d}")

# InterpretaciÃ³n de negocio
print(f"\nğŸ’¼ INTERPRETACIÃ“N DE NEGOCIO:")
print(f"   ğŸ“Š EstadÃ­sticas operacionales:")
print(f"      â€¢ Fraudes detectados correctamente: {tp} de {tp+fn} ({tp/(tp+fn)*100:.1f}%)")
print(f"      â€¢ Falsos positivos (falsa alarma): {fp}")
print(f"      â€¢ Fraudes no detectados (pÃ©rdida): {fn}")
print(f"      â€¢ Casos normales correctos: {tn}")

print(f"\n   ğŸ’° Impacto de negocio:")
fraud_detection_rate = tp / (tp + fn) * 100
false_positive_rate = fp / (fp + tn) * 100
print(f"      â€¢ Tasa de detecciÃ³n de fraude: {fraud_detection_rate:.1f}%")
print(f"      â€¢ Tasa de falsas alarmas: {false_positive_rate:.1f}%")

if final_recall >= 0.8:
    print("      âœ… EXCELENTE: Alta capacidad de detecciÃ³n de fraudes")
elif final_recall >= 0.6:
    print("      âš ï¸ BUENO: Capacidad moderada de detecciÃ³n")
else:
    print("      âŒ REQUIERE MEJORA: Baja detecciÃ³n de fraudes")

if final_precision >= 0.7:
    print("      âœ… EXCELENTE: Pocas falsas alarmas")
elif final_precision >= 0.5:
    print("      âš ï¸ ACEPTABLE: Falsas alarmas moderadas")
else:
    print("      âŒ PROBLEMÃTICO: Muchas falsas alarmas")

# ComparaciÃ³n con modelo original
print(f"\nğŸ“Š COMPARACIÃ“N CON METODOLOGÃA ORIGINAL:")
print(f"   ğŸ”„ Mejoras implementadas:")
print(f"      âœ… ImputaciÃ³n KNN vs llenar con 0")
print(f"      âœ… One-hot encoding vs asignaciÃ³n arbitraria") 
print(f"      âœ… Balanceo con SMOTE vs datos desbalanceados")
print(f"      âœ… MÃºltiples mÃ©tricas vs solo accuracy")
print(f"      âœ… OptimizaciÃ³n de hiperparÃ¡metros")
print(f"      âœ… Escalado de features")

# Recomendaciones finales
print(f"\nğŸš€ PRÃ“XIMOS PASOS Y RECOMENDACIONES:")
print(f"   ğŸ”§ Para mejorar el modelo:")
print(f"      â€¢ Feature engineering adicional (ratios, interacciones)")
print(f"      â€¢ Ensemble methods (combinaciÃ³n de modelos)")
print(f"      â€¢ AnÃ¡lisis de features mÃ¡s importantes")
print(f"      â€¢ Ajuste del threshold de clasificaciÃ³n segÃºn costos de negocio")

print(f"\n   ğŸ­ Para producciÃ³n:")
print(f"      â€¢ Pipeline automatizado de preprocesamiento")
print(f"      â€¢ Monitoreo de drift en datos")
print(f"      â€¢ Reentrenamiento periÃ³dico")
print(f"      â€¢ Sistema de alertas en tiempo real")
print(f"      â€¢ Feedback loop para mejorar continuamente")

print(f"\n   ğŸ“Š Monitoreo en producciÃ³n:")
print(f"      â€¢ Tracking de precision/recall mensual")
print(f"      â€¢ AnÃ¡lisis de falsos positivos por operadores")
print(f"      â€¢ Costos vs beneficios de detecciÃ³n")

# Feature importance (si es posible)
if hasattr(best_model_optimized, 'feature_importances_'):
    print(f"\nğŸ¯ TOP 10 FEATURES MÃS IMPORTANTES:")
    feature_names = X_train_balanced.columns
    importances = best_model_optimized.feature_importances_
    feature_importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': importances
    }).sort_values('importance', ascending=False)
    
    for i, (_, row) in enumerate(feature_importance_df.head(10).iterrows()):
        print(f"   {i+1:2d}. {row['feature']}: {row['importance']:.4f}")

print(f"\n" + "="*80)
print("âœ… ANÃLISIS COMPLETO FINALIZADO")
print("ğŸ‰ MODELO SUPERIOR DE DETECCIÃ“N DE FRAUDE IMPLEMENTADO")
print("="*80)

if __name__ == "__main__":
    print("\nğŸ“‹ ImplementaciÃ³n completa exitosa!")
    print("ğŸ’¾ Guardando modelo optimizado...")
    
    # Guardar el modelo y preprocessors para uso futuro
    import joblib
    
    # Guardar modelo
    joblib.dump(best_model_optimized, 'fraud_detection_model_optimized.pkl')
    joblib.dump(scaler, 'scaler.pkl')
    print("âœ… Modelo guardado como 'fraud_detection_model_optimized.pkl'")
    print("âœ… Scaler guardado como 'scaler.pkl'")
    
    # Crear resumen para reporte
    summary = {
        'best_model': best_model_name,
        'final_metrics': {
            'accuracy': final_accuracy,
            'precision': final_precision,
            'recall': final_recall,
            'f1_score': final_f1,
            'roc_auc': final_auc
        },
        'confusion_matrix': {
            'true_negatives': int(tn),
            'false_positives': int(fp),
            'false_negatives': int(fn),
            'true_positives': int(tp)
        },
        'business_impact': {
            'fraud_detection_rate': f"{fraud_detection_rate:.1f}%",
            'false_positive_rate': f"{false_positive_rate:.1f}%"
        }
    }
    
    import json
    with open('model_performance_summary.json', 'w') as f:
        json.dump(summary, f, indent=2)
    print("âœ… Resumen guardado como 'model_performance_summary.json'")