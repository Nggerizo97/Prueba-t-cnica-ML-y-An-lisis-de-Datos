#!/usr/bin/env python3
"""
Fraud Detection Model - Advanced Implementation
===============================================

Autor: Data Scientist Senior
Descripci√≥n: Implementaci√≥n mejorada para detecci√≥n de fraude que aborda las 
            debilidades del modelo original y proporciona una soluci√≥n robusta.

Este script implementa las 4 fases del an√°lisis:
1. Cr√≠tica Constructiva y Plan de Acci√≥n
2. Preprocesamiento de Datos Avanzado y Feature Engineering  
3. Modelado y Optimizaci√≥n
4. Evaluaci√≥n Rigurosa del Modelo y Conclusiones
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold, ParameterGrid
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import KNNImputer
from sklearn.metrics import (classification_report, confusion_matrix, 
                           precision_score, recall_score, f1_score, 
                           roc_auc_score, roc_curve, accuracy_score)
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("FRAUD DETECTION MODEL - ADVANCED IMPLEMENTATION")
print("="*80)

# =====================================================================
# FASE 1: CR√çTICA CONSTRUCTIVA Y PLAN DE ACCI√ìN
# =====================================================================

print("\n" + "="*60)
print("FASE 1: CR√çTICA CONSTRUCTIVA Y PLAN DE ACCI√ìN")
print("="*60)

print("""
AN√ÅLISIS CR√çTICO DE LA METODOLOG√çA ACTUAL:

1. MANEJO INADECUADO DE VALORES NULOS:
   ‚ùå Problema: Reemplazar todos los valores NaN por 0
   üîç Por qu√© es problem√°tico: 
      - Introduce sesgo artificial en el modelo
      - Puede crear patrones falsos donde no los hay
      - Diferentes variables requieren estrategias de imputaci√≥n distintas
   ‚úÖ Soluci√≥n: Imputaci√≥n sofisticada usando KNNImputer o estrategias espec√≠ficas

2. CODIFICACI√ìN INCORRECTA DE VARIABLES CATEG√ìRICAS:
   ‚ùå Problema: Asignar "pesos" num√©ricos arbitrarios a variables de texto
   üîç Por qu√© es problem√°tico:
      - Crea relaciones ordinales artificiales que no existen
      - El modelo interpreta incorrectamente la distancia entre categor√≠as
      - Puede llevr a conclusiones err√≥neas sobre importancia de features
   ‚úÖ Soluci√≥n: One-Hot Encoding est√°ndar

3. M√âTRICAS DE EVALUACI√ìN INSUFICIENTES:
   ‚ùå Problema: Solo usar precisi√≥n (accuracy) como m√©trica
   üîç Por qu√© es problem√°tico para fraude:
      - En datasets desbalanceados, accuracy puede ser muy enga√±osa
      - Un modelo que clasifica todo como "no fraude" podr√≠a tener 80% accuracy
      - No mide la capacidad real de detectar fraudes (recall)
   ‚úÖ Soluci√≥n: M√©tricas completas - Precision, Recall, F1-Score, ROC-AUC

4. FALTA DE MANEJO DEL DESBALANCE DE CLASES:
   ‚ùå Problema: No abordar el desbalance 63.5% vs 36.5%
   üîç Por qu√© es problem√°tico:
      - El modelo se sesga hacia la clase mayoritaria
      - Puede tener buen accuracy pero muy mal recall para fraudes
   ‚úÖ Soluci√≥n: SMOTE para balancear las clases

5. AUSENCIA DE PREPROCESAMIENTO AVANZADO:
   ‚ùå Problema: No escalar variables, no analizar correlaciones
   üîç Por qu√© es problem√°tico:
      - Algoritmos como Logistic Regression son sensibles a la escala
      - Variables con rangos diferentes dominan el modelo
   ‚úÖ Soluci√≥n: StandardScaler y an√°lisis de features

PLAN DE ACCI√ìN ESTRUCTURADO:
1. EDA completo con visualizaciones
2. Imputaci√≥n avanzada de valores faltantes  
3. Codificaci√≥n apropiada de categ√≥ricas
4. Escalado de features num√©ricas
5. Manejo del desbalance con SMOTE
6. Comparaci√≥n de m√∫ltiples algoritmos
7. Optimizaci√≥n de hiperpar√°metros
8. Evaluaci√≥n rigurosa con m√©tricas de negocio
""")

# =====================================================================
# FASE 2: PREPROCESAMIENTO DE DATOS AVANZADO Y FEATURE ENGINEERING
# =====================================================================

print("\n" + "="*60)
print("FASE 2: PREPROCESAMIENTO DE DATOS AVANZADO Y FEATURE ENGINEERING")
print("="*60)

# Cargar datos
print("üìä Cargando datasets...")
df_train = pd.read_excel('entrenamiento_fraude.xlsx')
df_test = pd.read_excel('testeo_fraude.xlsx')
df_eval = pd.read_excel('base_evaluada.xlsx')

print(f"‚úÖ Dataset entrenamiento: {df_train.shape}")
print(f"‚úÖ Dataset testeo: {df_test.shape}")  
print(f"‚úÖ Dataset evaluaci√≥n: {df_eval.shape}")

# EDA Inicial
print("\nüìà AN√ÅLISIS EXPLORATORIO INICIAL:")
print(f"Variables totales: {len(df_train.columns)}")
print(f"Variables num√©ricas: {len(df_train.select_dtypes(include=[np.number]).columns)}")
print(f"Variables categ√≥ricas: {len(df_train.select_dtypes(include=['object']).columns)}")
print(f"Valores faltantes totales: {df_train.isnull().sum().sum()}")

# An√°lisis del desbalance de clases
print("\n‚öñÔ∏è AN√ÅLISIS DEL BALANCE DE CLASES:")
class_distribution = df_train['fraude'].value_counts()
print(f"Clase 0 (No Fraude): {class_distribution[0]} ({class_distribution[0]/len(df_train)*100:.1f}%)")
print(f"Clase 1 (Fraude): {class_distribution[1]} ({class_distribution[1]/len(df_train)*100:.1f}%)")
print(f"Ratio de desbalance: {class_distribution[0]/class_distribution[1]:.2f}:1")

if class_distribution[0]/class_distribution[1] > 1.5:
    print("‚ö†Ô∏è DATASET DESBALANCEADO DETECTADO - Se aplicar√° SMOTE")
else:
    print("‚úÖ Dataset relativamente balanceado")

# Identificar variables categ√≥ricas
categorical_features = ['descri_apli_prod_ben', 'marca_timeout', 'marca_host_no_resp']
numerical_features = [col for col in df_train.columns 
                     if col not in categorical_features + ['radicado', 'fraude']]

print(f"\nüî§ Variables categ√≥ricas identificadas: {categorical_features}")
print(f"üî¢ Variables num√©ricas: {len(numerical_features)}")

# An√°lisis de valores faltantes por tipo de variable
print("\nüï≥Ô∏è AN√ÅLISIS DE VALORES FALTANTES:")
missing_analysis = df_train.isnull().sum()
missing_analysis = missing_analysis[missing_analysis > 0].sort_values(ascending=False)

for col, missing_count in missing_analysis.head(10).items():
    missing_pct = missing_count / len(df_train) * 100
    col_type = "categ√≥rica" if col in categorical_features else "num√©rica"
    print(f"   {col} ({col_type}): {missing_count} ({missing_pct:.1f}%)")

# Separar features y target
X = df_train.drop(['radicado', 'fraude'], axis=1)
y = df_train['fraude']

print("\nüîß APLICANDO PREPROCESAMIENTO AVANZADO...")

# 1. Estrategia de Imputaci√≥n Sofisticada
print("1Ô∏è‚É£ Imputaci√≥n avanzada de valores faltantes:")
print("   ‚Ä¢ Variables num√©ricas: KNNImputer (k=5) - m√°s sofisticado que mediana")
print("   ‚Ä¢ Variables categ√≥ricas: Moda (valor m√°s frecuente)")

# Para categ√≥ricas: imputar con moda
for col in categorical_features:
    if col in X.columns:
        mode_value = X[col].mode().iloc[0] if not X[col].mode().empty else 'Unknown'
        X[col] = X[col].fillna(mode_value)
        print(f"   ‚úÖ {col}: {X[col].isnull().sum()} valores faltantes restantes")

# Para num√©ricas: KNNImputer
numerical_cols_in_X = [col for col in numerical_features if col in X.columns]
if len(numerical_cols_in_X) > 0:
    knn_imputer = KNNImputer(n_neighbors=5)
    X[numerical_cols_in_X] = knn_imputer.fit_transform(X[numerical_cols_in_X])
    print(f"   ‚úÖ Variables num√©ricas: KNNImputer aplicado a {len(numerical_cols_in_X)} columnas")

print(f"   ‚úÖ Valores faltantes restantes: {X.isnull().sum().sum()}")

# 2. One-Hot Encoding para variables categ√≥ricas
print("\n2Ô∏è‚É£ One-Hot Encoding para variables categ√≥ricas:")
print("   üéØ Ventajas sobre asignaci√≥n de pesos:")
print("      ‚Ä¢ No crea relaciones ordinales artificiales")
print("      ‚Ä¢ Cada categor√≠a es independiente")
print("      ‚Ä¢ Interpretabilidad clara del modelo")

X_encoded = pd.get_dummies(X, columns=categorical_features, prefix=categorical_features, drop_first=True)
print(f"   ‚úÖ Dimensiones despu√©s de encoding: {X_encoded.shape}")
print(f"   ‚úÖ Nuevas columnas categ√≥ricas creadas: {X_encoded.shape[1] - len(numerical_cols_in_X)}")

# 3. Escalado de caracter√≠sticas
print("\n3Ô∏è‚É£ Escalado de caracter√≠sticas num√©ricas:")
print("   üéØ Importancia del escalado:")
print("      ‚Ä¢ Algoritmos como Logistic Regression son sensibles a la escala")
print("      ‚Ä¢ Mejora convergencia y performance")
print("      ‚Ä¢ Evita que variables con rangos grandes dominen el modelo")

scaler = StandardScaler()
numerical_cols_encoded = [col for col in X_encoded.columns if col in numerical_cols_in_X]
X_scaled = X_encoded.copy()
X_scaled[numerical_cols_encoded] = scaler.fit_transform(X_encoded[numerical_cols_encoded])
print(f"   ‚úÖ {len(numerical_cols_encoded)} variables num√©ricas escaladas")

# 4. Divisi√≥n de datos
print("\n4Ô∏è‚É£ Divisi√≥n estratificada de datos:")
X_train, X_val, y_train, y_val = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)
print(f"   ‚úÖ Entrenamiento: {X_train.shape[0]} muestras")
print(f"   ‚úÖ Validaci√≥n: {X_val.shape[0]} muestras")
print(f"   ‚úÖ Distribuci√≥n mantenida en ambos conjuntos")

# 5. Manejo del desbalance con SMOTE
print("\n5Ô∏è‚É£ Manejo del desbalance de clases con SMOTE:")
print("   üéØ SMOTE (Synthetic Minority Over-sampling Technique):")
print("      ‚Ä¢ Genera muestras sint√©ticas de la clase minoritaria")
print("      ‚Ä¢ Mejor que duplicar datos existentes")
print("      ‚Ä¢ Solo se aplica en entrenamiento, NO en validaci√≥n")

original_distribution = pd.Series(y_train).value_counts()
print(f"   üìä Distribuci√≥n original: {dict(original_distribution)}")

smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

balanced_distribution = pd.Series(y_train_balanced).value_counts()
print(f"   üìä Distribuci√≥n despu√©s de SMOTE: {dict(balanced_distribution)}")
print(f"   ‚úÖ Dataset balanceado: {X_train_balanced.shape[0]} muestras totales")

print("\nüéâ PREPROCESAMIENTO COMPLETADO:")
print(f"   ‚Ä¢ Datos finales entrenamiento: {X_train_balanced.shape}")
print(f"   ‚Ä¢ Features totales: {X_train_balanced.shape[1]}")
print(f"   ‚Ä¢ Clases balanceadas: ‚úÖ")
print(f"   ‚Ä¢ Datos escalados: ‚úÖ")
print(f"   ‚Ä¢ Variables categ√≥ricas codificadas: ‚úÖ")

# =====================================================================
# FASE 3: MODELADO Y OPTIMIZACI√ìN  
# =====================================================================

print("\n" + "="*60)
print("FASE 3: MODELADO Y OPTIMIZACI√ìN")
print("="*60)

print("\nü§ñ SELECCI√ìN Y COMPARACI√ìN DE ALGORITMOS:")
print("   üéØ Por qu√© m√∫ltiples algoritmos:")
print("      ‚Ä¢ Diferentes algoritmos capturan diferentes patrones")
print("      ‚Ä¢ Permite encontrar el mejor para este problema espec√≠fico")
print("      ‚Ä¢ Reduce overfitting y aumenta robustez")

# Definir modelos a comparar
models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),
    'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss')
}

print(f"\nüìã Algoritmos a evaluar:")
for name, model in models.items():
    print(f"   ‚Ä¢ {name}")

# Cross-validation strategy
cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
print(f"\nüîÑ Estrategia de validaci√≥n cruzada: {cv_strategy.n_splits}-fold estratificada")

# Evaluar modelos base
print("\nüèÉ‚Äç‚ôÇÔ∏è EVALUACI√ìN INICIAL DE MODELOS (sin optimizar):")
model_results = {}

for name, model in models.items():
    print(f"\n   üîç Evaluando {name}...")
    
    # Cross-validation scores
    cv_scores = cross_val_score(model, X_train_balanced, y_train_balanced, 
                               cv=cv_strategy, scoring='roc_auc', n_jobs=-1)
    
    # Fit model and predict on validation
    model.fit(X_train_balanced, y_train_balanced)
    y_pred = model.predict(X_val)
    y_pred_proba = model.predict_proba(X_val)[:, 1]
    
    # Calculate metrics
    accuracy = accuracy_score(y_val, y_pred)
    precision = precision_score(y_val, y_pred)
    recall = recall_score(y_val, y_pred)
    f1 = f1_score(y_val, y_pred)
    auc_score = roc_auc_score(y_val, y_pred_proba)
    
    model_results[name] = {
        'cv_auc_mean': cv_scores.mean(),
        'cv_auc_std': cv_scores.std(),
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'auc': auc_score,
        'model': model
    }
    
    print(f"      CV AUC: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")
    print(f"      Validaci√≥n - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}")

# Encontrar el mejor modelo base
best_model_name = max(model_results.keys(), key=lambda x: model_results[x]['cv_auc_mean'])
print(f"\nüèÜ MEJOR MODELO BASE: {best_model_name}")
print(f"   AUC promedio en CV: {model_results[best_model_name]['cv_auc_mean']:.4f}")

# Optimizaci√≥n de hiperpar√°metros para el mejor modelo
print(f"\n‚öôÔ∏è OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS - {best_model_name}:")
print("   üéØ GridSearchCV para encontrar la mejor combinaci√≥n de par√°metros")

if best_model_name == 'Logistic Regression':
    param_grid = {
        'C': [0.1, 1, 10],
        'penalty': ['l1', 'l2'],
        'solver': ['liblinear']
    }
elif best_model_name == 'Random Forest':
    param_grid = {
        'n_estimators': [100, 200],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1, 2]
    }
else:  # XGBoost
    param_grid = {
        'n_estimators': [100, 200],
        'max_depth': [3, 6],
        'learning_rate': [0.1, 0.2],
        'subsample': [0.8, 1.0]
    }

# GridSearch
print(f"   üîç Buscando entre {len(list(ParameterGrid(param_grid)))} combinaciones...")
best_base_model = models[best_model_name]
grid_search = GridSearchCV(
    best_base_model, param_grid, cv=cv_strategy, 
    scoring='roc_auc', n_jobs=-1, verbose=0
)

grid_search.fit(X_train_balanced, y_train_balanced)
best_model_optimized = grid_search.best_estimator_

print(f"   ‚úÖ Mejores par√°metros encontrados:")
for param, value in grid_search.best_params_.items():
    print(f"      {param}: {value}")
print(f"   ‚úÖ Mejor AUC en CV: {grid_search.best_score_:.4f}")

# =====================================================================
# FASE 4: EVALUACI√ìN RIGUROSA DEL MODELO Y CONCLUSIONES
# =====================================================================

print("\n" + "="*60)
print("FASE 4: EVALUACI√ìN RIGUROSA DEL MODELO Y CONCLUSIONES")
print("="*60)

print("\nüìä EVALUACI√ìN COMPLETA DEL MODELO OPTIMIZADO:")
print("   üéØ M√©tricas esenciales para detecci√≥n de fraude:")
print("      ‚Ä¢ Precision: ¬øQu√© % de alertas de fraude son realmente fraude?")
print("      ‚Ä¢ Recall: ¬øQu√© % de fraudes reales detectamos?")
print("      ‚Ä¢ F1-Score: Balance entre Precision y Recall")
print("      ‚Ä¢ ROC-AUC: Capacidad discriminativa general")

# Predicciones finales
y_pred_final = best_model_optimized.predict(X_val)
y_pred_proba_final = best_model_optimized.predict_proba(X_val)[:, 1]

# M√©tricas finales
final_accuracy = accuracy_score(y_val, y_pred_final)
final_precision = precision_score(y_val, y_pred_final)
final_recall = recall_score(y_val, y_pred_final)
final_f1 = f1_score(y_val, y_pred_final)
final_auc = roc_auc_score(y_val, y_pred_proba_final)

print(f"\nüìà M√âTRICAS FINALES DEL MODELO OPTIMIZADO:")
print(f"   ‚Ä¢ Accuracy: {final_accuracy:.4f} ({final_accuracy*100:.1f}%)")
print(f"   ‚Ä¢ Precision: {final_precision:.4f} ({final_precision*100:.1f}%)")
print(f"   ‚Ä¢ Recall: {final_recall:.4f} ({final_recall*100:.1f}%)")
print(f"   ‚Ä¢ F1-Score: {final_f1:.4f}")
print(f"   ‚Ä¢ ROC-AUC: {final_auc:.4f}")

# Matriz de confusi√≥n
print(f"\nüéØ MATRIZ DE CONFUSI√ìN:")
cm = confusion_matrix(y_val, y_pred_final)
tn, fp, fn, tp = cm.ravel()

print(f"                 Predicci√≥n")
print(f"               No Fraude  Fraude")
print(f"Real No Fraude    {tn:4d}    {fp:4d}")
print(f"Real Fraude       {fn:4d}    {tp:4d}")

# Interpretaci√≥n de negocio
print(f"\nüíº INTERPRETACI√ìN DE NEGOCIO:")
print(f"   üìä Estad√≠sticas operacionales:")
print(f"      ‚Ä¢ Fraudes detectados correctamente: {tp} de {tp+fn} ({tp/(tp+fn)*100:.1f}%)")
print(f"      ‚Ä¢ Falsos positivos (falsa alarma): {fp}")
print(f"      ‚Ä¢ Fraudes no detectados (p√©rdida): {fn}")
print(f"      ‚Ä¢ Casos normales correctos: {tn}")

print(f"\n   üí∞ Impacto de negocio:")
fraud_detection_rate = tp / (tp + fn) * 100
false_positive_rate = fp / (fp + tn) * 100
print(f"      ‚Ä¢ Tasa de detecci√≥n de fraude: {fraud_detection_rate:.1f}%")
print(f"      ‚Ä¢ Tasa de falsas alarmas: {false_positive_rate:.1f}%")

if final_recall >= 0.8:
    print("      ‚úÖ EXCELENTE: Alta capacidad de detecci√≥n de fraudes")
elif final_recall >= 0.6:
    print("      ‚ö†Ô∏è BUENO: Capacidad moderada de detecci√≥n")
else:
    print("      ‚ùå REQUIERE MEJORA: Baja detecci√≥n de fraudes")

if final_precision >= 0.7:
    print("      ‚úÖ EXCELENTE: Pocas falsas alarmas")
elif final_precision >= 0.5:
    print("      ‚ö†Ô∏è ACEPTABLE: Falsas alarmas moderadas")
else:
    print("      ‚ùå PROBLEM√ÅTICO: Muchas falsas alarmas")

# Comparaci√≥n con modelo original
print(f"\nüìä COMPARACI√ìN CON METODOLOG√çA ORIGINAL:")
print(f"   üîÑ Mejoras implementadas:")
print(f"      ‚úÖ Imputaci√≥n KNN vs llenar con 0")
print(f"      ‚úÖ One-hot encoding vs asignaci√≥n arbitraria") 
print(f"      ‚úÖ Balanceo con SMOTE vs datos desbalanceados")
print(f"      ‚úÖ M√∫ltiples m√©tricas vs solo accuracy")
print(f"      ‚úÖ Optimizaci√≥n de hiperpar√°metros")
print(f"      ‚úÖ Escalado de features")

# Recomendaciones finales
print(f"\nüöÄ PR√ìXIMOS PASOS Y RECOMENDACIONES:")
print(f"   üîß Para mejorar el modelo:")
print(f"      ‚Ä¢ Feature engineering adicional (ratios, interacciones)")
print(f"      ‚Ä¢ Ensemble methods (combinaci√≥n de modelos)")
print(f"      ‚Ä¢ An√°lisis de features m√°s importantes")
print(f"      ‚Ä¢ Ajuste del threshold de clasificaci√≥n seg√∫n costos de negocio")

print(f"\n   üè≠ Para producci√≥n:")
print(f"      ‚Ä¢ Pipeline automatizado de preprocesamiento")
print(f"      ‚Ä¢ Monitoreo de drift en datos")
print(f"      ‚Ä¢ Reentrenamiento peri√≥dico")
print(f"      ‚Ä¢ Sistema de alertas en tiempo real")
print(f"      ‚Ä¢ Feedback loop para mejorar continuamente")

print(f"\n   üìä Monitoreo en producci√≥n:")
print(f"      ‚Ä¢ Tracking de precision/recall mensual")
print(f"      ‚Ä¢ An√°lisis de falsos positivos por operadores")
print(f"      ‚Ä¢ Costos vs beneficios de detecci√≥n")

# Feature importance (si es posible)
if hasattr(best_model_optimized, 'feature_importances_'):
    print(f"\nüéØ TOP 10 FEATURES M√ÅS IMPORTANTES:")
    feature_names = X_train_balanced.columns
    importances = best_model_optimized.feature_importances_
    feature_importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': importances
    }).sort_values('importance', ascending=False)
    
    for i, (_, row) in enumerate(feature_importance_df.head(10).iterrows()):
        print(f"   {i+1:2d}. {row['feature']}: {row['importance']:.4f}")

print(f"\n" + "="*80)
print("‚úÖ AN√ÅLISIS COMPLETO FINALIZADO")
print("üéâ MODELO SUPERIOR DE DETECCI√ìN DE FRAUDE IMPLEMENTADO")
print("="*80)

if __name__ == "__main__":
    print("\nüìã Implementaci√≥n completa exitosa!")
    print("üíæ Guardando modelo optimizado...")
    
    # Guardar el modelo y preprocessors para uso futuro
    import joblib
    
    # Guardar modelo
    joblib.dump(best_model_optimized, 'fraud_detection_model_optimized.pkl')
    joblib.dump(scaler, 'scaler.pkl')
    print("‚úÖ Modelo guardado como 'fraud_detection_model_optimized.pkl'")
    print("‚úÖ Scaler guardado como 'scaler.pkl'")
    
    # Crear resumen para reporte
    summary = {
        'best_model': best_model_name,
        'final_metrics': {
            'accuracy': final_accuracy,
            'precision': final_precision,
            'recall': final_recall,
            'f1_score': final_f1,
            'roc_auc': final_auc
        },
        'confusion_matrix': {
            'true_negatives': int(tn),
            'false_positives': int(fp),
            'false_negatives': int(fn),
            'true_positives': int(tp)
        },
        'business_impact': {
            'fraud_detection_rate': f"{fraud_detection_rate:.1f}%",
            'false_positive_rate': f"{false_positive_rate:.1f}%"
        }
    }
    
    import json
    with open('model_performance_summary.json', 'w') as f:
        json.dump(summary, f, indent=2)
    print("‚úÖ Resumen guardado como 'model_performance_summary.json'")