{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DetecciÃ³n de Fraude - ImplementaciÃ³n Avanzada\n",
    "## AnÃ¡lisis de CientÃ­fico de Datos Senior\n",
    "\n",
    "Este notebook implementa una soluciÃ³n robusta y superior para la detecciÃ³n de fraude, abordando las debilidades del modelo original y proporcionando una metodologÃ­a completa de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 1: CrÃ­tica Constructiva del Modelo Original\n",
    "\n",
    "### Problemas Identificados:\n",
    "1. **Manejo inadecuado de valores nulos**: Reemplazar por 0 introduce sesgo\n",
    "2. **CodificaciÃ³n incorrecta de categÃ³ricas**: AsignaciÃ³n arbitraria de nÃºmeros\n",
    "3. **MÃ©tricas insuficientes**: Solo accuracy, ignorando precision/recall\n",
    "4. **Desbalance no tratado**: 63.5% vs 36.5% sin SMOTE\n",
    "5. **Falta de preprocesamiento**: Sin escalado ni feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerÃ­as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                           precision_score, recall_score, f1_score, \n",
    "                           roc_auc_score, roc_curve, accuracy_score)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ConfiguraciÃ³n de grÃ¡ficos\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 2: Carga y AnÃ¡lisis Exploratorio de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datasets\n",
    "df_train = pd.read_excel('entrenamiento_fraude.xlsx')\n",
    "df_test = pd.read_excel('testeo_fraude.xlsx')\n",
    "df_eval = pd.read_excel('base_evaluada.xlsx')\n",
    "\n",
    "print(f\"Dataset entrenamiento: {df_train.shape}\")\n",
    "print(f\"Dataset testeo: {df_test.shape}\")\n",
    "print(f\"Dataset evaluaciÃ³n: {df_eval.shape}\")\n",
    "\n",
    "# AnÃ¡lisis del balance de clases\n",
    "class_distribution = df_train['fraude'].value_counts()\n",
    "print(f\"\\nBalance de clases:\")\n",
    "print(f\"No Fraude (0): {class_distribution[0]} ({class_distribution[0]/len(df_train)*100:.1f}%)\")\n",
    "print(f\"Fraude (1): {class_distribution[1]} ({class_distribution[1]/len(df_train)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualizaciÃ³n del balance de clases\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# GrÃ¡fico de barras\n",
    "class_distribution.plot(kind='bar', ax=ax1)\n",
    "ax1.set_title('DistribuciÃ³n de Clases')\n",
    "ax1.set_xlabel('Clase (0=No Fraude, 1=Fraude)')\n",
    "ax1.set_ylabel('NÃºmero de Casos')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# GrÃ¡fico de pie\n",
    "ax2.pie(class_distribution.values, labels=['No Fraude', 'Fraude'], autopct='%1.1f%%')\n",
    "ax2.set_title('ProporciÃ³n de Clases')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Ratio de desbalance: {class_distribution[0]/class_distribution[1]:.2f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lisis de valores faltantes\n",
    "missing_data = df_train.isnull().sum()\n",
    "missing_data = missing_data[missing_data > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(missing_data) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    missing_data.plot(kind='bar')\n",
    "    plt.title('Valores Faltantes por Variable')\n",
    "    plt.xlabel('Variables')\n",
    "    plt.ylabel('NÃºmero de Valores Faltantes')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Variables con valores faltantes: {len(missing_data)}\")\n",
    "    print(f\"Total de valores faltantes: {missing_data.sum()}\")\nelse:\n",
    "    print(\"No hay valores faltantes en el dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 2: Preprocesamiento Avanzado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar tipos de variables\n",
    "categorical_features = ['descri_apli_prod_ben', 'marca_timeout', 'marca_host_no_resp']\n",
    "numerical_features = [col for col in df_train.columns \n",
    "                     if col not in categorical_features + ['radicado', 'fraude']]\n",
    "\n",
    "print(f\"Variables categÃ³ricas: {len(categorical_features)}\")\n",
    "print(f\"Variables numÃ©ricas: {len(numerical_features)}\")\n",
    "\n",
    "# Separar features y target\n",
    "X = df_train.drop(['radicado', 'fraude'], axis=1)\n",
    "y = df_train['fraude']\n",
    "\n",
    "print(f\"\\nShape de X: {X.shape}\")\n",
    "print(f\"Shape de y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ImputaciÃ³n avanzada\n",
    "print(\"ðŸ”§ Aplicando imputaciÃ³n avanzada...\")\n",
    "\n",
    "# Para categÃ³ricas: moda\n",
    "for col in categorical_features:\n",
    "    if col in X.columns:\n",
    "        mode_value = X[col].mode().iloc[0] if not X[col].mode().empty else 'Unknown'\n",
    "        X[col] = X[col].fillna(mode_value)\n",
    "        print(f\"âœ… {col}: Imputado con moda\")\n",
    "\n",
    "# Para numÃ©ricas: KNNImputer\n",
    "numerical_cols_in_X = [col for col in numerical_features if col in X.columns]\n",
    "if len(numerical_cols_in_X) > 0:\n",
    "    knn_imputer = KNNImputer(n_neighbors=5)\n",
    "    X[numerical_cols_in_X] = knn_imputer.fit_transform(X[numerical_cols_in_X])\n",
    "    print(f\"âœ… Variables numÃ©ricas: KNNImputer aplicado\")\n",
    "\n",
    "print(f\"Valores faltantes restantes: {X.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. One-Hot Encoding\n",
    "print(\"ðŸ”§ Aplicando One-Hot Encoding...\")\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_features, prefix=categorical_features, drop_first=True)\n",
    "print(f\"Dimensiones despuÃ©s de encoding: {X_encoded.shape}\")\n",
    "\n",
    "# 3. Escalado\n",
    "print(\"ðŸ”§ Aplicando escalado...\")\n",
    "scaler = StandardScaler()\n",
    "numerical_cols_encoded = [col for col in X_encoded.columns if col in numerical_cols_in_X]\n",
    "X_scaled = X_encoded.copy()\n",
    "X_scaled[numerical_cols_encoded] = scaler.fit_transform(X_encoded[numerical_cols_encoded])\n",
    "print(f\"Variables numÃ©ricas escaladas: {len(numerical_cols_encoded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. DivisiÃ³n de datos\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"ValidaciÃ³n: {X_val.shape[0]} muestras\")\n",
    "\n",
    "# 5. SMOTE para balancear\n",
    "print(\"\\nðŸ”§ Aplicando SMOTE...\")\n",
    "original_distribution = pd.Series(y_train).value_counts()\n",
    "print(f\"DistribuciÃ³n original: {dict(original_distribution)}\")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "balanced_distribution = pd.Series(y_train_balanced).value_counts()\n",
    "print(f\"DistribuciÃ³n despuÃ©s de SMOTE: {dict(balanced_distribution)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 3: Modelado y OptimizaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# EvaluaciÃ³n inicial\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model_results = {}\n",
    "\n",
    "print(\"ðŸƒâ€â™‚ï¸ Evaluando modelos base...\")\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluando {name}...\")\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_balanced, y_train_balanced, \n",
    "                               cv=cv_strategy, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    # Fit y predict\n",
    "    model.fit(X_train_balanced, y_train_balanced)\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # MÃ©tricas\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    auc_score = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'cv_auc_mean': cv_scores.mean(),\n",
    "        'cv_auc_std': cv_scores.std(),\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc_score\n",
    "    }\n",
    "    \n",
    "    print(f\"CV AUC: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ComparaciÃ³n visual de modelos\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# AUC\n",
    "axes[0,0].bar(results_df.index, results_df['cv_auc_mean'])\n",
    "axes[0,0].set_title('AUC Score (Cross-Validation)')\n",
    "axes[0,0].set_ylabel('AUC')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Precision\n",
    "axes[0,1].bar(results_df.index, results_df['precision'])\n",
    "axes[0,1].set_title('Precision')\n",
    "axes[0,1].set_ylabel('Precision')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Recall\n",
    "axes[1,0].bar(results_df.index, results_df['recall'])\n",
    "axes[1,0].set_title('Recall')\n",
    "axes[1,0].set_ylabel('Recall')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# F1-Score\n",
    "axes[1,1].bar(results_df.index, results_df['f1'])\n",
    "axes[1,1].set_title('F1-Score')\n",
    "axes[1,1].set_ylabel('F1-Score')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mejor modelo\n",
    "best_model_name = max(model_results.keys(), key=lambda x: model_results[x]['cv_auc_mean'])\n",
    "print(f\"\\nðŸ† Mejor modelo: {best_model_name}\")\n",
    "print(f\"AUC: {model_results[best_model_name]['cv_auc_mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OptimizaciÃ³n de hiperparÃ¡metros\n",
    "print(f\"âš™ï¸ Optimizando hiperparÃ¡metros para {best_model_name}...\")\n",
    "\n",
    "if best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "    base_model = RandomForestClassifier(random_state=42)\n",
    "elif best_model_name == 'Logistic Regression':\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    }\n",
    "    base_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "else:  # XGBoost\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 6],\n",
    "        'learning_rate': [0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    }\n",
    "    base_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    base_model, param_grid, cv=cv_strategy, \n",
    "    scoring='roc_auc', n_jobs=-1, verbose=0\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"âœ… Mejores parÃ¡metros: {grid_search.best_params_}\")\n",
    "print(f\"âœ… Mejor AUC: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 4: EvaluaciÃ³n Rigurosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones finales\n",
    "y_pred_final = best_model.predict(X_val)\n",
    "y_pred_proba_final = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# MÃ©tricas finales\n",
    "final_accuracy = accuracy_score(y_val, y_pred_final)\n",
    "final_precision = precision_score(y_val, y_pred_final)\n",
    "final_recall = recall_score(y_val, y_pred_final)\n",
    "final_f1 = f1_score(y_val, y_pred_final)\n",
    "final_auc = roc_auc_score(y_val, y_pred_proba_final)\n",
    "\n",
    "print(\"ðŸ“ˆ MÃ‰TRICAS FINALES:\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f} ({final_accuracy*100:.1f}%)\")\n",
    "print(f\"Precision: {final_precision:.4f} ({final_precision*100:.1f}%)\")\n",
    "print(f\"Recall: {final_recall:.4f} ({final_recall*100:.1f}%)\")\n",
    "print(f\"F1-Score: {final_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {final_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusiÃ³n\n",
    "cm = confusion_matrix(y_val, y_pred_final)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Fraude', 'Fraude'],\n",
    "            yticklabels=['No Fraude', 'Fraude'])\n",
    "plt.title('Matriz de ConfusiÃ³n')\n",
    "plt.xlabel('PredicciÃ³n')\n",
    "plt.ylabel('Real')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ’¼ INTERPRETACIÃ“N DE NEGOCIO:\")\n",
    "print(f\"Fraudes detectados correctamente: {tp} de {tp+fn} ({tp/(tp+fn)*100:.1f}%)\")\n",
    "print(f\"Falsos positivos (falsa alarma): {fp}\")\n",
    "print(f\"Fraudes no detectados (pÃ©rdida): {fn}\")\n",
    "print(f\"Casos normales correctos: {tn}\")\n",
    "\n",
    "fraud_detection_rate = tp / (tp + fn) * 100\n",
    "false_positive_rate = fp / (fp + tn) * 100\n",
    "print(f\"\\nTasa de detecciÃ³n de fraude: {fraud_detection_rate:.1f}%\")\n",
    "print(f\"Tasa de falsas alarmas: {false_positive_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba_final)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {final_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (si disponible)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_names = X_train_balanced.columns\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Top 15 features\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = feature_importance_df.head(15)\n",
    "    sns.barplot(data=top_features, y='feature', x='importance')\n",
    "    plt.title('Top 15 Features MÃ¡s Importantes')\n",
    "    plt.xlabel('Importancia')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ðŸŽ¯ TOP 10 FEATURES MÃS IMPORTANTES:\")\n",
    "    for i, (_, row) in enumerate(feature_importance_df.head(10).iterrows()):\n",
    "        print(f\"{i+1:2d}. {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AplicaciÃ³n del Modelo al Dataset de Testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesar dataset de testeo con la misma metodologÃ­a\n",
    "print(\"ðŸ”§ Preprocesando dataset de testeo...\")\n",
    "\n",
    "# Separar features del dataset de testeo\n",
    "X_test_raw = df_test.drop(['radicado'], axis=1)\n",
    "\n",
    "# 1. ImputaciÃ³n (mismo mÃ©todo)\n",
    "for col in categorical_features:\n",
    "    if col in X_test_raw.columns:\n",
    "        mode_value = X[col].mode().iloc[0] if not X[col].mode().empty else 'Unknown'\n",
    "        X_test_raw[col] = X_test_raw[col].fillna(mode_value)\n",
    "\n",
    "# Para numÃ©ricas: usar el mismo imputer entrenado\n",
    "numerical_cols_test = [col for col in numerical_features if col in X_test_raw.columns]\n",
    "if len(numerical_cols_test) > 0:\n",
    "    X_test_raw[numerical_cols_test] = knn_imputer.transform(X_test_raw[numerical_cols_test])\n",
    "\n",
    "# 2. One-Hot Encoding (asegurar mismas columnas)\n",
    "X_test_encoded = pd.get_dummies(X_test_raw, columns=categorical_features, prefix=categorical_features, drop_first=True)\n",
    "\n",
    "# Asegurar que tengas las mismas columnas que en entrenamiento\n",
    "missing_cols = set(X_encoded.columns) - set(X_test_encoded.columns)\n",
    "for col in missing_cols:\n",
    "    X_test_encoded[col] = 0\n",
    "\n",
    "# Reordenar columnas\n",
    "X_test_encoded = X_test_encoded[X_encoded.columns]\n",
    "\n",
    "# 3. Escalado (usar el mismo scaler)\n",
    "X_test_scaled = X_test_encoded.copy()\n",
    "numerical_cols_test_encoded = [col for col in X_test_encoded.columns if col in numerical_cols_encoded]\n",
    "X_test_scaled[numerical_cols_test_encoded] = scaler.transform(X_test_encoded[numerical_cols_test_encoded])\n",
    "\n",
    "print(f\"âœ… Dataset de testeo preprocesado: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones en el dataset de testeo\n",
    "print(\"ðŸ”® Realizando predicciones en dataset de testeo...\")\n",
    "\n",
    "test_predictions = best_model.predict(X_test_scaled)\n",
    "test_probabilities = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'radicado': df_test['radicado'],\n",
    "    'fraude_prediccion': test_predictions,\n",
    "    'probabilidad_fraude': test_probabilities\n",
    "})\n",
    "\n",
    "# EstadÃ­sticas de predicciones\n",
    "pred_distribution = pd.Series(test_predictions).value_counts()\n",
    "print(f\"\\nðŸ“Š RESULTADOS EN DATASET DE TESTEO:\")\n",
    "print(f\"Total de casos: {len(test_predictions)}\")\n",
    "print(f\"Predicciones No Fraude (0): {pred_distribution.get(0, 0)} ({pred_distribution.get(0, 0)/len(test_predictions)*100:.1f}%)\")\n",
    "print(f\"Predicciones Fraude (1): {pred_distribution.get(1, 0)} ({pred_distribution.get(1, 0)/len(test_predictions)*100:.1f}%)\")\n",
    "\n",
    "# Mostrar casos con mayor probabilidad de fraude\n",
    "print(f\"\\nðŸš¨ TOP 10 CASOS CON MAYOR PROBABILIDAD DE FRAUDE:\")\n",
    "top_fraud_cases = results_df.nlargest(10, 'probabilidad_fraude')\n",
    "for idx, row in top_fraud_cases.iterrows():\n",
    "    print(f\"Radicado: {row['radicado']}, Probabilidad: {row['probabilidad_fraude']:.4f}\")\n",
    "\n",
    "# Guardar resultados\n",
    "results_df.to_excel('predicciones_fraude_mejoradas.xlsx', index=False)\n",
    "print(f\"\\nðŸ’¾ Resultados guardados en 'predicciones_fraude_mejoradas.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualizaciÃ³n de distribuciÃ³n de probabilidades\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histograma de probabilidades\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(test_probabilities, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('DistribuciÃ³n de Probabilidades de Fraude')\n",
    "plt.xlabel('Probabilidad de Fraude')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.axvline(x=0.5, color='red', linestyle='--', label='Threshold = 0.5')\n",
    "plt.legend()\n",
    "\n",
    "# Boxplot por predicciÃ³n\n",
    "plt.subplot(1, 2, 2)\n",
    "results_df.boxplot(column='probabilidad_fraude', by='fraude_prediccion', ax=plt.gca())\n",
    "plt.title('Probabilidades por PredicciÃ³n')\n",
    "plt.xlabel('PredicciÃ³n (0=No Fraude, 1=Fraude)')\n",
    "plt.ylabel('Probabilidad de Fraude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones y Recomendaciones\n",
    "\n",
    "### Mejoras Implementadas vs Modelo Original:\n",
    "1. âœ… **ImputaciÃ³n KNN** vs llenar con 0\n",
    "2. âœ… **One-hot encoding** vs asignaciÃ³n arbitraria\n",
    "3. âœ… **Balanceo con SMOTE** vs datos desbalanceados\n",
    "4. âœ… **MÃºltiples mÃ©tricas** vs solo accuracy\n",
    "5. âœ… **OptimizaciÃ³n de hiperparÃ¡metros**\n",
    "6. âœ… **Escalado de features**\n",
    "\n",
    "### PrÃ³ximos Pasos:\n",
    "- Feature engineering adicional\n",
    "- Ensemble methods\n",
    "- Ajuste de threshold segÃºn costos de negocio\n",
    "- Pipeline de producciÃ³n automatizado\n",
    "- Monitoreo continuo del modelo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}